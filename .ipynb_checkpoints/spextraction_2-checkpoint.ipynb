{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759515b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from scipy.interpolate import interp1d\n",
    "import math\n",
    "from pylanetary.navigation import *\n",
    "from pylanetary.utils import *\n",
    "from uncertainties.umath import *\n",
    "from uncertainties import unumpy\n",
    "from scipy import interpolate\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from astroquery.jplhorizons import Horizons\n",
    "import astropy.units as u\n",
    "import math\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The below functions will generate spectrum files to be used as input for a radiative transfer model. At the moment, the only avialable format is for NEMESIS, and much of the code is catered to IRTF SpeX Guidedog images. Should still be generally applicable and easy to add more options later. Individual functions have doc strings explaining inputs and outputs. To make spectra, run spectrum_file_maker() at the end of the notebook after compiling the other functions.\n",
    "\n",
    "To run this code:\n",
    "1. Install pylanetary into a new conda environment: https://github.com/emolter/pylanetary/tree/main\n",
    "2. Install uncertainties package into that environment: \n",
    "    $ conda activate pylanetary-tester\n",
    "    $ pip install uncertainties\n",
    "3. Run this code within that conda environment (to implement it within a jupyter notebook, use https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084)\n",
    "\n",
    "There are comments flagged with !! throughout that should go into a big to-do list, or that might become issues later.\n",
    "Biggest oustanding issues:\n",
    "-in spectral extraction, issue w/ mu going above 1. I don't think those spectra are equally spaced in mu\n",
    "-Conversion to radiance/I/F, solar spectrum to use?\n",
    "-Adding more options for implementing specta, probably a readme file for using those input files\n",
    "-Eventually adding the ability to calculate azimuth and solar zenith angle to pylanetary; will make projposolar and its auxiliary code unnecessary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions used within map_maker() to generate maps.\n",
    "\n",
    "def interceptellip(a,b,alpha,beta,gamma,x0,y0,z0):\n",
    "    '''\n",
    "    ; **********************************************************\n",
    "    ; procedure to find the intercepts (if any) between the line\n",
    "    ;\n",
    "    ;  (x-x0)       (y-y0)      (z-z0)\n",
    "    ;  ------  =    ------   =  ------\n",
    "    ;  alpha         beta       gamma\n",
    "    ; \n",
    "    ; and the ellipsoid\n",
    "    ;\n",
    "    ;\n",
    "    ;  x^2    y^2    z^2   \n",
    "    ;  --- +  --- +  ---  = 1\n",
    "    ;  a^2    a^2    b^2\n",
    "    ;\n",
    "    ; Input variables\n",
    "    ;       a       real    ellipsoid semi-major axis\n",
    "    ;       b       real    ellipsoid semi-minor axis\n",
    "    ;       alpha   real    line x-gradient\n",
    "    ;       beta    real    line y-gradient\n",
    "    ;       gamma   real    line z-gradient\n",
    "    ;       x0      real    line x-intercept\n",
    "    ;       y0      real    line y-intercept\n",
    "    ;       z0      real    line z-intercept\n",
    "    ;\n",
    "    ; Output variables\n",
    "    ;       iflag   integer Set to 1 if line intercepts, set to -1  otherwise\n",
    "    ;       x(2)    real    x-intercepts\n",
    "    ;       y(2)    real    y-intercepts\n",
    "    ;       z(2)    real    z-intercepts\n",
    "    ;\n",
    "    ; Pat Irwin     11/2/07\n",
    "    ; Python conversion - Emma Dahl 3-8-19\n",
    "    ; **********************************************************\n",
    "    '''\n",
    "    a1 = 1.0/a**2 + (beta/(a*alpha))**2 + (gamma/(b*alpha))**2\n",
    "\n",
    "    b1 = (-2*x0*beta**2/alpha**2 + 2*beta*y0/alpha)/a**2\n",
    "    b1 = b1 + (-2*x0*gamma**2/alpha**2 + 2*gamma*z0/alpha)/b**2\n",
    "    \n",
    "    c1 = ((beta*x0/alpha)**2 - 2*beta*y0*x0/alpha + y0**2)/a**2\n",
    "    c1 = c1 + ((gamma*x0/alpha)**2 - 2*gamma*x0*z0/alpha + z0**2)/b**2 -1\n",
    "        \n",
    "    #;print,a1,1.0/a**2 + (gamma/(b*alpha))**2\n",
    "    #;print,b1,2*gamma*z0/(alpha*b**2)\n",
    "    #;print,c1,(y0/a)**2 + (z0/b)**2 -1\n",
    "    \n",
    "    xtest = b1**2 - 4*a1*c1\n",
    "\n",
    "    x = np.zeros(2)\n",
    "    y = np.zeros(2)\n",
    "    z = np.zeros(2)\n",
    "        \n",
    "    if xtest > 0.0:\n",
    "        iflag = 1\n",
    "        x[0] = (-b1 + np.sqrt(xtest))/(2*a1)\n",
    "        x[1] = (-b1 - np.sqrt(xtest))/(2*a1)\n",
    "        y[0] = y0 + (beta/alpha)*(x[0]-x0)\n",
    "        y[1] = y0 + (beta/alpha)*(x[1]-x0)\n",
    "        z[0] = z0 + (gamma/alpha)*(x[0]-x0)\n",
    "        z[1] = z0 + (gamma/alpha)*(x[1]-x0)\n",
    "\n",
    "        # testing to see if solution is on ellipsoid\n",
    "        test=np.ndarray(len(x))\n",
    "        for i in range(0,len(x)):\n",
    "            test[i] = (x[i]/a)**2 + (y[i]/a)**2 + (z[i]/b)**2\n",
    "        xtest1 = abs(test[0]-1.0)\n",
    "        xtest2 = abs(test[1]-1.0)\n",
    "        \n",
    "        err = 1e-5\n",
    "        \n",
    "        if xtest1 > err or xtest2 > err:\n",
    "            print('Problem in interceptellip - solution not on ellipsoid')\n",
    "            print('Test =',test)\n",
    "    else:\n",
    "        iflag = -1\n",
    "\n",
    "\n",
    "    return iflag,x,y,z\n",
    "\n",
    "interceptellip_vec = np.vectorize(interceptellip)\n",
    "\n",
    "def projposolar(Re,obl,epsilon,latsol,lonsol,se_lon,eoff,poff):\n",
    "    '''\n",
    "    ; ************************************************************\n",
    "    ; Procedure to find latitude and longitude and zenith angle of\n",
    "    ; intercept between line and ellipsoid\n",
    "    ;\n",
    "    ; Input variables\n",
    "    ;       Re      real    Equatorial Radius (arcsec)\n",
    "    ;       obl     real    Planetary oblateness\n",
    "    ;       epsilon real    Sub-observer (planetocentric) latitude\n",
    "    ;       latsol  real    Sub-solar planetocentric latitude\n",
    "    ;       lonsol  real    longitude difference between sub-solar and sub-observer\n",
    "    ;                       points.\n",
    "    ;       se_lon  real    Sub-observer longitude # added by Emma\n",
    "    ;       eoff    real    equatorial offset of beam (arcsec)\n",
    "    ;       poff    real    polar offset of beam (arcsec)\n",
    "    ;\n",
    "    ; Output variables\n",
    "    ;       iflag   integer Set to 1 if real intercept, -1 otherwise\n",
    "    ;       xlat    real    Planetocentric latitude\n",
    "    ;       longitude real  xlon+se_lon, offset of longitude added to sub-observer longitude # added by Emma\n",
    "    ;       xlon    real    Longitude\n",
    "    ;       zen     real    Zenith angle\n",
    "    ;       szen    real    Solar zenith angle\n",
    "    ;       aphi    real    local azimuth angle between sun and observer\n",
    "    ;\n",
    "    ; Pat Irwin     11/2/07\n",
    "    ; Python conversion - Emma Dahl 3/8/19\n",
    "    ; ************************************************************\n",
    "    '''\n",
    "    \n",
    "    dtr = np.pi/180.0 # radians/degrees\n",
    "    Rp = Re*(1.0-obl)\n",
    "    \n",
    "    x0 = 0.0\n",
    "    y0 = eoff\n",
    "    z0 = poff/np.cos(epsilon*dtr)\n",
    "    \n",
    "    alpha = np.sin(np.pi/2.0 - epsilon*dtr)\n",
    "    beta = 0.0\n",
    "    gamma = np.cos(np.pi/2.0 - epsilon*dtr)\n",
    "    \n",
    "    # commenting out to give program my own iflag map\n",
    "    iflag,x,y,z = interceptellip_vec(Re,Rp,alpha,beta,gamma,x0,y0,z0)\n",
    "    #print(iflag)\n",
    "    \n",
    "    xlat = 0.0\n",
    "    xlon = 0.0\n",
    "    zen = 0.0\n",
    "    \n",
    "    # !!! getting rid of iflag statement here because I already have the maps set up for real intercepts below\n",
    "    #if iflag > 0:\n",
    "    # if real intercept, find lat, long, and zenith\n",
    "\n",
    "    # find distance along line of sight\n",
    "    lambdaa = (x-x0)/alpha\n",
    "    if lambdaa[0] > lambdaa[1]:\n",
    "        inear = 0\n",
    "    else:\n",
    "        inear = 1\n",
    "\n",
    "    x1 = x[inear]\n",
    "    y1 = y[inear]\n",
    "    z1 = z[inear]\n",
    "\n",
    "    r = np.sqrt(x1**2 + y1**2 + z1**2)\n",
    "\n",
    "    theta = np.arccos(z1/r)\n",
    "    xlat = 90.0 - theta/dtr\n",
    "\n",
    "    #; convert to planetographic latitude\n",
    "    #; xlat = np.arctan(((Re/Rp)**2)*np.tan(xlat*dtr))/dtr\n",
    "\n",
    "    cphi = x1/(r*np.sin(theta))\n",
    "\n",
    "    if cphi > 1.0:\n",
    "        cphi = 1.0\n",
    "    if cphi < -1.0:\n",
    "        cphi = -1.0\n",
    "\n",
    "    phi = np.arccos(cphi)\n",
    "    if y1 < 0.0:\n",
    "        phi = -phi\n",
    "    xlon = phi/dtr        \n",
    "\n",
    "    # Finding aphi, zen, szen - don't mess with these, want to still output them\n",
    "\n",
    "    v1 = np.zeros(3)\n",
    "    v2 = np.zeros(3)\n",
    "    v3 = np.zeros(3)\n",
    "\n",
    "    # v1 is normal vector of point observed\n",
    "    v1[0] = x1/r\n",
    "    v1[1] = y1/r\n",
    "    v1[2] = z1/r\n",
    "\n",
    "    v2[0] = alpha\n",
    "    v2[1] = beta\n",
    "    v2[2] = gamma\n",
    "\n",
    "    summ = 0.0\n",
    "\n",
    "    for i in range(0,3):\n",
    "        summ += v1[i]*v2[i]\n",
    "    zen = np.arccos(summ)/dtr\n",
    "\n",
    "    # Finding aphi\n",
    "\n",
    "    alphasol = np.sin(np.pi/2.0 - latsol*dtr)*np.cos(lonsol*dtr)\n",
    "    betasol =  np.sin(np.pi/2.0 - latsol*dtr)*np.sin(lonsol*dtr)\n",
    "    gammasol = np.cos(np.pi/2 - latsol*dtr)\n",
    "    v3[0]=alphasol\n",
    "    v3[1]=betasol\n",
    "    v3[2]=gammasol\n",
    "\n",
    "    summ = 0.0\n",
    "    for i in range(0,3):\n",
    "        summ += v1[i]*v3[i]\n",
    "    szen = np.arccos(summ)/dtr\n",
    "\n",
    "    cphase = 0.0\n",
    "\n",
    "    for i in range(0,3):\n",
    "        cphase += v2[i]*v3[i]\n",
    "\n",
    "    a = np.cos(zen*dtr)*np.cos(szen*dtr)\n",
    "    b = np.sin(zen*dtr)*np.sin(szen*dtr)\n",
    "\n",
    "    if b == 0.0:\n",
    "        aphi = 180.0\n",
    "    else:\n",
    "        cphi = (cphase-a)/b\n",
    "        aphi = 180.0-np.arccos(cphi)/dtr\n",
    "            \n",
    "    longitude = se_lon-xlon # offset of longitude added to sub-observer longitude\n",
    "    # Remember that system III longitude increases to the west\n",
    "    \n",
    "    #return xlat,longitude\n",
    "    return iflag,xlat,longitude,xlon,zen,szen,aphi\n",
    "    #return xlat,longitude,xlon,zen,szen,aphi\n",
    "\n",
    "projposolar_vec = np.vectorize(projposolar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_finder(filename, ut_date='DATE_OBS', ut_time='TIME_OBS', target_name='Jupiter', location_code='568'):\n",
    "    '''\n",
    "    Queries horizons and produces distance in AU. Just copied relevant content from map_maker().\n",
    "    \n",
    "    Input:\n",
    "    filename - string, path+name of fits file to map.    \n",
    "    \n",
    "    optional keyword arguments; defaults are those used by IRTF SpeX Guidedog camera\n",
    "    ut_date - string, the header keyword for UT date of the observation\n",
    "    ut_time - string, the header keyword for the average UT time of the observation\n",
    "    target_name - string, planet being observed. so far just the gas giants are included. Adding more will require including more of the planets and their corresponding Horizons codes in the planets variable.\n",
    "    location_code - string, horizons code of observing location. default = 568, Mauna Kea \n",
    "    \n",
    "    output:\n",
    "    distance to planet in AU\n",
    "    '''\n",
    "    planets = ('599','Jupiter',71492,66854,0.06487),('699','Saturn',60268,54364,0.09796),('799','Uranus',25559,24973,0.0229),('899','Neptune',24766,24342,0.0171)\n",
    "    \n",
    "    # import image\n",
    "    im = fits.open(filename)\n",
    "    header = im[0].header\n",
    "\n",
    "    # based on UT time/date and location of observations, query Horizons for viewing geom info\n",
    "    UT_date = header[ut_date]; UT_time = header[ut_time]; target = target_name\n",
    "    \n",
    "    # Account for fractional seconds in UT_time if it exists. datetime does not like fractional seconds.\n",
    "    if '.' in UT_time:\n",
    "        nofrag, frag = UT_time.split('.')\n",
    "        UT_time = nofrag    \n",
    "\n",
    "    # Query horizons. !! The date/time format for UT_date and UT_time as used in date_obj are specific to the format used by the IRTF.\n",
    "    for k in planets: # find planet code, r_eq, r_pol, obl\n",
    "        if k[1] == target: # assumes target string is exactly correct.\n",
    "            id_number = k[0]; planet_label = k[1]; req = k[2]; rpol = k[3]; obl = k[4]\n",
    "\n",
    "    # calculate julian date\n",
    "    date_obj = datetime.strptime(UT_date+' '+UT_time, '%Y-%m-%d %H:%M:%S') # define datetime object based on UT date and time. Might have issue bc seconds are fractional\n",
    "    date_only_obj = datetime.strptime(UT_date, '%Y-%m-%d')\n",
    "    h = int(date_obj.strftime(\"%H\")); m = int(date_obj.strftime(\"%M\")); s = int(date_obj.strftime(\"%S\"))\n",
    "    dt = timedelta(hours=h, minutes=m, seconds=s)\n",
    "    secs_per_day = 24*60*60    # hours * mins * secs\n",
    "    jd_time_fraction = dt.total_seconds()/secs_per_day # fraction of day time, to add to date\n",
    "\n",
    "    jd = date_only_obj.toordinal() + 1721424.5 + jd_time_fraction # based on https://stackoverflow.com/questions/13943062/extract-day-of-year-and-julian-day-from-a-string-date\n",
    "\n",
    "    # put ephimerides into a table\n",
    "    table = Horizons(id=id_number, location=location_code, epochs=jd).ephemerides()\n",
    "    distance_au = table['delta'][0]\n",
    "    \n",
    "    return distance_au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3e840",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def map_maker(filename, plot_maps=0,  ut_date='DATE_OBS', ut_time='TIME_OBS', target_name='Jupiter', location_code='568', pixelscale=0.115696):\n",
    "    \n",
    "    '''\n",
    "    Program to generate viewing geometry maps. Will first query Horizons for \n",
    "    \n",
    "    Inputs\n",
    "    -----------\n",
    "    filename - string, path+name of fits file to map.\n",
    "    plot_maps - 0 or 1, int. on/off switch for plotting diagnostic plots. 0 = no plots, 1 = plots.\n",
    "    \n",
    "    optional keyword arguments; defaults are those used by IRTF SpeX Guidedog camera\n",
    "    ut_date - string, the header keyword for UT date of the observation\n",
    "    ut_time - string, the header keyword for the average UT time of the observation\n",
    "    target - string, planet being observed. so far just the gas giants are included. Adding more will require including more of the planets and their corresponding Horizons codes in the planets variable.\n",
    "    location_code - string, horizons code of observing location. default = 568, Mauna Kea\n",
    "    pixelscale - float, pixel scale of instrument in \"/pix. Default is guidedog on IRTF SpeX\n",
    "    \n",
    "    Outputs\n",
    "    -----------\n",
    "    iflag - 2D array, map of planet location. 1 where planet is, -1 where planet is not. !! save my self-made iflag map?\n",
    "    latitude_final - 2D array, float, planetocentric latitude. nans everywhere else\n",
    "    longitude_final - 2D array, float, sys III longitude (increases to west). nans everywhere else\n",
    "    xlon - 2D array, longitude offset from meridian. nans everywhere else\n",
    "    zen - 2D array of zenith emission angle. nans everywhere else\n",
    "    szen - 2D array of soalr emission angle. nans everywhere else\n",
    "    aphi - 2D array of azimuth angle. nans everywhere else\n",
    "    data - 2D array of cropped, rotated, and aligned data. nans everywhere else\n",
    "    ob_lon - sub-observer longitude (lcm in later functions)\n",
    "    distance_au - distance to Jupiter in AU from the Earth (needed for spectrum file)\n",
    "    '''\n",
    "    \n",
    "    print('Loading image info and querying Horizons...')\n",
    "    \n",
    "    #tuples of planets and their Horizons codes. Only gas giants for now, can add terrestrial planets. Horizons code, name, equatorial radius (km), polar radius (km), oblateness. would be nice to be able to pull radii from horizons eventually\n",
    "    planets = ('599','Jupiter',71492,66854,0.06487),('699','Saturn',60268,54364,0.09796),('799','Uranus',25559,24973,0.0229),('899','Neptune',24766,24342,0.0171)\n",
    "    \n",
    "    # import image\n",
    "    im = fits.open(filename)\n",
    "    header = im[0].header\n",
    "    data = im[0].data\n",
    "    if plot_maps == 1:\n",
    "        plt.imshow(data,origin='lower')\n",
    "        plt.title('original data')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # based on UT time/date and location of observations, query Horizons for viewing geom info\n",
    "    UT_date = header[ut_date] \n",
    "    UT_time = header[ut_time]\n",
    "    target = target_name\n",
    "    #target = header[target_keyword] # !! would like to make this query the header, but might generate some issues if target names aren't recorded the same across different datasets. \n",
    "\n",
    "    # Account for fractional seconds in UT_time if it exists. datetime does not like fractional seconds.\n",
    "    if '.' in UT_time:\n",
    "        nofrag, frag = UT_time.split('.')\n",
    "        UT_time = nofrag    \n",
    "\n",
    "    # Query horizons. !! The date/time format for UT_date and UT_time as used in date_obj are specific to the format used by the IRTF.\n",
    "\n",
    "    for k in planets: # find planet code, r_eq, r_pol, obl\n",
    "        if k[1] == target: # assumes target string is exactly correct. might be an issue if there are additional spaces\n",
    "            id_number = k[0]; planet_label = k[1]; req = k[2]; rpol = k[3]; obl = k[4]\n",
    "\n",
    "    # calculate julian date\n",
    "    date_obj = datetime.strptime(UT_date+' '+UT_time, '%Y-%m-%d %H:%M:%S') # define datetime object based on UT date and time. Might have issue bc seconds are fractional\n",
    "    date_only_obj = datetime.strptime(UT_date, '%Y-%m-%d')\n",
    "    h = int(date_obj.strftime(\"%H\"))\n",
    "    m = int(date_obj.strftime(\"%M\"))\n",
    "    s = int(date_obj.strftime(\"%S\"))\n",
    "    dt = timedelta(hours=h, minutes=m, seconds=s)\n",
    "    secs_per_day = 24*60*60    # hours * mins * secs\n",
    "    jd_time_fraction = dt.total_seconds()/secs_per_day # fraction of day time, to add to date\n",
    "\n",
    "    jd = date_only_obj.toordinal() + 1721424.5 + jd_time_fraction # based on https://stackoverflow.com/questions/13943062/extract-day-of-year-and-julian-day-from-a-string-date\n",
    "\n",
    "    # define horizons query\n",
    "    obj = Horizons(id=id_number, location=location_code, epochs=jd)\n",
    "\n",
    "    # put ephimerides into a table\n",
    "    table = obj.ephemerides()\n",
    "    distance_au = table['delta'][0]\n",
    "    distance = table['delta'][0]*1.496E8 # in AU, convert to km\n",
    "\n",
    "    # define values needed for ModelEllopsoid\n",
    "    ob_lon = table['PDObsLon'][0] #sub-observer longitude, degrees\n",
    "    ob_lat = table['PDObsLat'][0] #sub-observer latitude, degrees, planetocentric\n",
    "    sol_lon = table['PDSunLon'][0] #sub-solar longitude, degrees\n",
    "    sol_lat = table['PDSunLat'][0] #sub-solar latitude, degrees, planetocentric\n",
    "    pixscale_km = np.arctan(pixelscale*(1/206265))*distance\n",
    "    np_ang = table['NPole_ang'][0] #degrees \n",
    "\n",
    "    # save values of values needed for projposolar, outside of eoff and poff. gratiutous but I'm tired\n",
    "    Re = (req/pixscale_km)*pixelscale # equatorial radius in arcsec\n",
    "    epsilon = ob_lat # Sub-observer (planetographic) latitude\n",
    "    latsol = sol_lat # Sub-solar planetocentric latitude\n",
    "    lonsol = sol_lon-ob_lon # longitude difference between sub-solar and sub-observer points\n",
    "\n",
    "    # define offset and rotation values to be used for both data and iflag map rotation\n",
    "    # !! hard coded planet center value keywords for IRTF\n",
    "    cx = im[0].header['cx']; cy = im[0].header['cy']\n",
    "    # x and y center of image\n",
    "    x1 = im[0].header['naxis1']/2; y1 = im[0].header['naxis2']/2\n",
    "    x_offset = int(cx-x1); y_offset = int(cy-y1)\n",
    "    rot_ang = np.copy(np_ang)\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # begin generating iflag map using nav, rotate and crop\n",
    "\n",
    "    # use pylanetary to generate map of where planet is and isn't, Might not need all lines here but keeping anyways to make sure nothing breaks\n",
    "    obs_time = UT_date + ' ' + UT_time\n",
    "    ellipsoid = ModelEllipsoid(ob_lon, ob_lat, pixscale_km, np_ang, req, rpol)\n",
    "    body = Body(target, epoch=obs_time, location=location_code) \n",
    "    model = ModelBody(body, pixelscale, shape=(len(data),len(data[0])))\n",
    "    nav = Nav(data, body, pixelscale)\n",
    "\n",
    "    # use nav.mu to make iflag map. rotated_mu_map will ultimately become iflag_map\n",
    "    rotated_mu_map = np.copy(nav.mu)\n",
    "    rotated_mu_map[np.where(np.isnan(rotated_mu_map)==True)] = 0 # make nans 0 so ndimage doesn't freak out.\n",
    "    # rotate\n",
    "    rotated_mu_map = ndimage.rotate(rotated_mu_map,rot_ang)\n",
    "\n",
    "    # crop; ! might want to just use the same crop values for both data and iflag centeirng?\n",
    "    if len(rotated_mu_map) > header['naxis1'] or len(rotated_mu_map[0]) > header['naxis2']:\n",
    "        x_crop = int((len(rotated_mu_map)-header['naxis1'])/2)\n",
    "        y_crop = int((len(rotated_mu_map[0])-header['naxis2'])/2)\n",
    "        rotated_mu_map = rotated_mu_map[x_crop:-x_crop,y_crop:-y_crop]\n",
    "\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # rotate and crop data after it's been used to orient the iflag map\n",
    "    # rotate and center image \n",
    "    data=np.roll(data,-y_offset,axis=0)\n",
    "    data=np.roll(data,-x_offset,axis=1)\n",
    "\n",
    "    data = ndimage.rotate(data,np_ang)\n",
    "\n",
    "    # crop centered and rotated data\n",
    "    if len(data) > header['naxis1'] or len(data[0]) > header['naxis2']:\n",
    "        x_crop = int((len(data)-header['naxis1'])/2)\n",
    "        y_crop = int((len(data[0])-header['naxis2'])/2)\n",
    "        data = data[x_crop:-x_crop,y_crop:-y_crop]\n",
    "    np_ang_orig = np.copy(np_ang)\n",
    "    # update rotation angle and offset since data has been rotated and aligned\n",
    "    np_ang = 0\n",
    "    x_offset = 0; y_offset = 0\n",
    "\n",
    "    if plot_maps == 1:\n",
    "        plt.imshow(data,origin='lower')\n",
    "        plt.title('centered rotated and cropped data')\n",
    "        plt.show()\n",
    "        \n",
    "    # make sure iflag map and data have the same dimensions (otherwise will have issues mapping arrays later)\n",
    "    if len(data) != len(rotated_mu_map) or len(data[0]) != len(rotated_mu_map[0]):\n",
    "        print('! size of iflag map and data are not equal !')\n",
    "        print('len(data):',len(data),'rotated_mu_map:',len(rotated_mu_map))\n",
    "        print('len(data[0]):',len(data[0]),'rotated_mu_map[0]:',len(rotated_mu_map[0]))\n",
    "        # if wrong numbers but ~1 pixel off, it's probably fine (if we're looking at Jupiter with plenty of pixels to spare)\n",
    "\n",
    "    # use the rotated mu map to finish making iflag_map.\n",
    "    # since using nd image rotate on 0's, very close to 0, rounding down. !!! very janky, likely a more elegant way to do this. \n",
    "    iflag_map = np.copy(rotated_mu_map)\n",
    "    iflag_map = np.round(iflag_map,1)\n",
    "    iflag_map[np.where(iflag_map==0)] = 0\n",
    "    iflag_map[np.where(iflag_map!=0)] = 1\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # find eoff and poff, equatorial and polar offset needed for projposolar. Much of this is originally from working with tricky rotation so mostly unnecessart now, but leaving in in case we want to implement it later.\n",
    "\n",
    "    # finding center point based on data array (should be same as x1 and y1 earlier?)\n",
    "    x_center = len(data)/2\n",
    "    y_center = len(data[0])/2\n",
    "\n",
    "    # don't need but might be helpful for testing\n",
    "    unrot_x = np.where(iflag_map==1)[0]\n",
    "    unrot_y = np.where(iflag_map==1)[1]\n",
    "\n",
    "    # list of coordinates where the planet is. Shifted to have origin at middle of image/planet\n",
    "    x = unrot_x-x_center\n",
    "    y = unrot_y-y_center\n",
    "\n",
    "    np_ang_radians = np_ang*0.0174533 # rad/deg # in case still need to rotate. should be 0 if data already rotated\n",
    "\n",
    "    # flipped these bc lat and long maps where backwards\n",
    "    eoff = -x*np.sin(np_ang_radians)+y*np.cos(np_ang_radians)\n",
    "    poff = x*np.cos(np_ang_radians)+y*np.sin(np_ang_radians)\n",
    "    \n",
    "    # translate the pixel offsets to arcsec offsets    \n",
    "    eoff*=pixelscale \n",
    "    poff*=pixelscale\n",
    "\n",
    "    # map eoff and poff values onto planet pixel locations using iflag\n",
    "    eoff_final = np.copy(iflag_map)\n",
    "    poff_final = np.copy(iflag_map)\n",
    "\n",
    "    eoff_final[np.where(iflag_map==1)] = eoff\n",
    "    poff_final[np.where(iflag_map==1)] = poff\n",
    "\n",
    "    eoff_final[np.where(iflag_map!=1)] = np.nan\n",
    "    poff_final[np.where(iflag_map!=1)] = np.nan\n",
    "\n",
    "    if plot_maps == 1: # commented out bc not really necessary. Helpful for assessing issues though\n",
    "        plt.imshow(eoff_final,origin='lower')\n",
    "        plt.title('equatorial offset in arcsec')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.imshow(poff_final,origin='lower')\n",
    "        plt.colorbar()\n",
    "        plt.title('polar offset in arcsec')\n",
    "        plt.show()\n",
    "\n",
    "    # run projposolar, usng iflag map to find location of planet pixels\n",
    "    print('Generating maps...(ignore following errors, they are accounted for w/ iflag map)')\n",
    "\n",
    "    # will get mad if passed nans\n",
    "    # generate maps of all the following values:\n",
    "    iflag,latitude_final,longitude_final,xlon,zen,szen,aphi = projposolar_vec(Re,obl,epsilon,latsol,lonsol,ob_lon,eoff_final,poff_final)\n",
    "\n",
    "    # flip maps along vertical axis (probably more elegant way to do this)\n",
    "    szen=np.flip(szen,axis=1)\n",
    "    aphi=np.flip(aphi,axis=1)\n",
    "    \n",
    "    if plot_maps == 1:\n",
    "        plt.imshow(iflag,origin='lower')\n",
    "        plt.colorbar(label='iflag')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(latitude_final,origin='lower')\n",
    "        plt.colorbar(label='Latitude')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(longitude_final,origin='lower')\n",
    "        plt.colorbar(label='Longitude (Sys III)')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(zen,origin='lower')\n",
    "        plt.colorbar(label='Zenith emission angle')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(szen,origin='lower')\n",
    "        plt.colorbar(label='Solar zenith angle')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(aphi,origin='lower')\n",
    "        plt.colorbar(label='Azimuth angle')\n",
    "        plt.show()\n",
    "\n",
    "    return iflag,latitude_final,longitude_final,xlon,zen,szen,aphi,data,ob_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a450c5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test:\n",
    "iflag,latitude_final,longitude_final,xlon,zen,szen,aphi,data,lcm = map_maker('/Users/emmadahl/Desktop/spextraction/test_data/jupiter/jcf01170125.gz.fits',plot_maps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302d5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd091d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spex_wavelengths(filename):\n",
    "    '''\n",
    "    Routine to find the correct wavelength for a SpeX Guidedog image given certain OS filter and G filter combos.\n",
    "    wavelength: midpoint originally from table at http://irtfweb.ifa.hawaii.edu/~spex/work/filters/filters.html (but link seems to be broken now)\n",
    "    \n",
    "    input\n",
    "    -filename: string, path+name of fits file to read. presumption is that this is a guidedog image.\n",
    "    \n",
    "    output\n",
    "    -Wavelength float. mircons\n",
    "    will return error if no matching wavelength is found\n",
    "    '''\n",
    "    wavelength = -1\n",
    "    \n",
    "    im = fits.open(filename)\n",
    "    header = im[0].header\n",
    "    osfilt = header['OSF']\n",
    "    gfilt = header['GFLT']\n",
    "    \n",
    "    if gfilt == 'Open':\n",
    "        # define list of tuples\n",
    "        wavelength_tuple = (('Open',0.00),('Blank',0.00),('PK-50',2.5), ('Opt',2.5),  ('0.1',0.1), ('Long4',5.2), ('Long5',3.86), ('Long6',3.33), ('Short3',2.22), ('Short4',1.63), ('Short5',1.27), ('Short6',1.15), ('Short7',.95), ('CH4_l' ,1.69), ('CH4_s',1.58))\n",
    "        for j in wavelength_tuple:\n",
    "            if j[0] == osfilt:\n",
    "                wavelength = j[1]\n",
    "                return wavelength\n",
    "        \n",
    "    elif gfilt == 'H' and osfilt == 'CH4_s':\n",
    "        wavelength = 1.58\n",
    "        return wavelength\n",
    "    elif gfilt == 'H' and osfilt == 'CH4_l':\n",
    "        wavelength = 1.69\n",
    "        return wavelength\n",
    "        \n",
    "    else:\n",
    "        # define list of tuples\n",
    "        wavelength_tuple = (('Open',0.00), ('Blank',0.00), ('Z',1.00),('J',1.215), ('H',1.654), ('K',2.23), (\"L'\",3.80), ('Lp',3.80), (\"M'\",4.76) ,('FeII',1.64), ('H2',2.12), ('Bry',2.16), ('contK',2.26), ('CO',2.29), (\"M'+ND1\",4.76), ('3.417',3.417), ('3.454',3.454), ('5.1',5.100))\n",
    "        for j in wavelength_tuple:\n",
    "            if j[0] == gfilt:\n",
    "                wavelength = j[1]\n",
    "                return wavelength\n",
    "        \n",
    "    if wavelength == -1:\n",
    "        print('Error! No matching wavelength found for filter combo by spex_wavelengths()')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_saver(dictionary,key,map_save_location,wl):\n",
    "    '''\n",
    "    just saves the map of mapvalue (e.g. aphi, zen, etc.) to a file. Making this a routine to avoid copying the same 3 lines over and over    \n",
    "\n",
    "    dictionary - wavelength dictionary of map dictionaries\n",
    "    key - string, label of map, will be used as key to pull that array\n",
    "    map_save_location - string, path of location to save maps\n",
    "    wl - wavelength of dictionary of dictionaries\n",
    "    '''\n",
    "    wl = str(wl)\n",
    "    wl_dict = dictionary[wl]\n",
    "    np.savetxt(map_save_location+key+'_'+str(wl),wl_dict[key+'_'+str(wl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spextraction_images(format_file, data_list, map_save_location, wavelength_keyword='OSF', plot_maps=0, map_save=0, map_load=0):\n",
    "    # !!! change map_save_location\n",
    "    '''    \n",
    "    Extract spectra based on user input, using maps generated by map_maker(). This version is for extracting spectra from images. Maybe make other versions later?\n",
    "    \n",
    "    --------------------\n",
    "    Input:\n",
    "    format_file - string, path+name of input file. contains code for what kind of spectra to make (1=equal mu bins within a given latitude/longitude bin). For now, only 1 format but will change that.\n",
    "    data_list - input file containing paths+names of images to extract spectra from. Proabbly just want one image per wavelength and grouped together in time (up to the user how to do that). Will sort by wavelength here so no need to do that in the input file. Will assume that the list contains images of the same target. \n",
    "    plot_maps - on/off switch, int. Will plot maps\n",
    "    \n",
    "    saving/loading things: take advantage of this! otherwise takes a while to make maps new every time.\n",
    "    map_save - int, on/off switch. 1, will save maps to path defined by map_save_location. 0, won't.\n",
    "    load_maps - int, on/off switch. 1, will load maps from path defined by map_save_location. 0, won't.\n",
    "    map_save_location - path to location of saved maps. \n",
    "    \n",
    "    output:\n",
    "    arrays for each image/wavelength\n",
    "    \n",
    "    # !! lots of comments with !! need attention. didn't bother to write htem here as to-do items\n",
    "    but lcm is acting real weird. since we're doing meridian\n",
    "    '''\n",
    "    \n",
    "    datalist = np.loadtxt(data_list,dtype=str) # load list of images\n",
    "    guidedog_wavelengths = () # list of tuples that correspond to the filters used and corresponding wavelengths. OSF, GFLT, and then WL # !! might not use this\n",
    "    \n",
    "    # sort images by wavelength\n",
    "    wl = []\n",
    "    image = []\n",
    "    if wavelength_keyword == 'OSF': # if spex guidedog images\n",
    "        for j in datalist:\n",
    "            wl.append(spex_wavelengths(j))\n",
    "            image.append(j)\n",
    "    else:\n",
    "        for j in datalist:\n",
    "            im = fits.open(j)\n",
    "            wl.append(im[0].header[wavelength_keyword])\n",
    "            image.append(j)\n",
    "    # sort images based on wavelength\n",
    "    wl_sorted_images = [x for _,x in sorted(zip(wl,image))]\n",
    "    wavelengths_sorted = sorted(wl)\n",
    "    \n",
    "    print(wavelengths_sorted)\n",
    "    \n",
    "    # open input file and determine type of spectrum to make\n",
    "    with open(format_file,'r') as f:\n",
    "        all_data=[x.split() for x in f.readlines()]\n",
    "        spec_type = int(all_data[0][0]) # find and define\n",
    "        if spec_type == 1:\n",
    "            # if mu-binned lat spectrum, find other requirements:\n",
    "            lat_min = float(all_data[1][0])\n",
    "            lat_max = float(all_data[1][1])\n",
    "            mu_min = float(all_data[2][0])\n",
    "            n_bins = int(all_data[3][0])\n",
    "            meridian_switch = float(all_data[4][0])\n",
    "            w_mu = float(all_data[5][0])\n",
    "            \n",
    "        elif spec_type == 2:\n",
    "            # if different kind of spectrum, do something else. Fill this in later.\n",
    "            return\n",
    "            \n",
    "    \n",
    "    # - - - - - - - - - - - Map saving/loading\n",
    "    \n",
    "    # make maps for each image/wavelength. Is there a way to write this avoid making new maps every time? save them somewhere with the obs_time in the file name, and we can check to see if it's been saved somewhere already.\n",
    "    map_dict = {}\n",
    "    for i in range(0,len(wl_sorted_images)):\n",
    "        print('Arranging map info for',str(wavelengths_sorted[i]))\n",
    "        if map_load == 1:\n",
    "            map_dict_dummy = {}\n",
    "            # load each map for that wavelength and save it to the dictionary\n",
    "            iflag = np.loadtxt(map_save_location+'iflag_'+str(wavelengths_sorted[i]))\n",
    "            latitude_final = np.loadtxt(map_save_location+'latitude_final_'+str(wavelengths_sorted[i]))\n",
    "            longitude_final = np.loadtxt(map_save_location+'longitude_final_'+str(wavelengths_sorted[i]))\n",
    "            zen = np.loadtxt(map_save_location+'zen_'+str(wavelengths_sorted[i]))\n",
    "            szen = np.loadtxt(map_save_location+'szen_'+str(wavelengths_sorted[i]))\n",
    "            aphi = np.loadtxt(map_save_location+'aphi_'+str(wavelengths_sorted[i]))\n",
    "            mu = np.loadtxt(map_save_location+'mu_'+str(wavelengths_sorted[i]))\n",
    "            data = np.loadtxt(map_save_location+'data_'+str(wavelengths_sorted[i]))\n",
    "            lcm = np.loadtxt(map_save_location+'lcm_'+str(wavelengths_sorted[i]))\n",
    "            \n",
    "            map_dict_dummy['iflag_'+str(wavelengths_sorted[i])] = iflag\n",
    "            map_dict_dummy['latitude_final_'+str(wavelengths_sorted[i])] = latitude_final\n",
    "            map_dict_dummy['longitude_final_'+str(wavelengths_sorted[i])] = longitude_final \n",
    "            map_dict_dummy['zen_'+str(wavelengths_sorted[i])] = zen \n",
    "            map_dict_dummy['szen_'+str(wavelengths_sorted[i])] = szen\n",
    "            map_dict_dummy['aphi_'+str(wavelengths_sorted[i])] = aphi\n",
    "            map_dict_dummy['mu_'+str(wavelengths_sorted[i])] = mu\n",
    "            map_dict_dummy['data_'+str(wavelengths_sorted[i])] = data\n",
    "            map_dict_dummy['lcm_'+str(wavelengths_sorted[i])] = lcm\n",
    "            map_dict[str(wavelengths_sorted[i])] = map_dict_dummy\n",
    "            \n",
    "        else: # otherwise, make a dictionary of maps for that wavelength\n",
    "            map_dict_dummy = {}\n",
    "            iflag,latitude_final,longitude_final,xlon,zen,szen,aphi,data,lcm = map_maker(wl_sorted_images[i],plot_maps)\n",
    "                        \n",
    "            map_dict_dummy['iflag_'+str(wavelengths_sorted[i])] = iflag\n",
    "            map_dict_dummy['latitude_final_'+str(wavelengths_sorted[i])] = latitude_final\n",
    "            map_dict_dummy['longitude_final_'+str(wavelengths_sorted[i])] = longitude_final \n",
    "            map_dict_dummy['zen_'+str(wavelengths_sorted[i])] = zen \n",
    "            map_dict_dummy['szen_'+str(wavelengths_sorted[i])] = szen\n",
    "            map_dict_dummy['aphi_'+str(wavelengths_sorted[i])] = aphi\n",
    "            map_dict_dummy['mu_'+str(wavelengths_sorted[i])] = np.cos(zen*0.0174533)\n",
    "            map_dict_dummy['data_'+str(wavelengths_sorted[i])] = data\n",
    "            # code is getting mad that lcm isn't an array. i'm tired so here is the bad fix\n",
    "            lcm_array = np.copy(data)\n",
    "            lcm_array[:,:] = lcm\n",
    "            map_dict_dummy['lcm_'+str(wavelengths_sorted[i])] = lcm_array\n",
    "            map_dict[str(wavelengths_sorted[i])] = map_dict_dummy            \n",
    "            \n",
    "            # option to save maps\n",
    "            if map_save == 1:\n",
    "                print('Saving maps at '+str(wavelengths_sorted[i])+'...')\n",
    "                map_saver(map_dict,'iflag',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'latitude_final',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'longitude_final',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'zen',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'szen',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'aphi',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'mu',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'data',map_save_location,wavelengths_sorted[i])\n",
    "                map_saver(map_dict,'lcm',map_save_location,wavelengths_sorted[i])\n",
    "                # if normal file.write() stuff works in map_saver: map_saver(iflag,map_save_location,wavelengths_sorted[i])\n",
    "                          \n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - \n",
    "    # # find mu_max from an example map. Does this need to be done at each wavelength? probably fine.\n",
    "    wl_dummy = wavelengths_sorted[0]\n",
    "    mu_map = map_dict[str(wl_dummy)]['mu_'+str(wl_dummy)]\n",
    "    lat_map = map_dict[str(wl_dummy)]['latitude_final_'+str(wl_dummy)]\n",
    "    data_map = map_dict[str(wl_dummy)]['data_'+str(wl_dummy)]\n",
    "\n",
    "    coordinates = np.where((lat_map<lat_max) & (lat_map>lat_min)) \n",
    "\n",
    "    mu_max = np.max(mu_map[coordinates])\n",
    "    \n",
    "    if plot_maps == 1:\n",
    "        new=np.copy(mu_map); new2=np.copy(mu_map); data_test = np.copy(data_map); data_test2 = np.copy(data_map)\n",
    "\n",
    "        new[coordinates] = 5000\n",
    "        new_coordinates = np.where(new<5000) \n",
    "\n",
    "        data_test[coordinates] = np.nan # blank out data we're sampling\n",
    "        data_test2[new_coordinates] = np.nan # show only data we're sampling. Looks smaller but don't worry, will be fine\n",
    "\n",
    "        print('Region of spectral extraction:')\n",
    "        plt.imshow(new,origin='lower')\n",
    "        plt.show()\n",
    "        plt.imshow(data_test,origin='lower')\n",
    "        plt.show()\n",
    "        plt.imshow(data_test2,origin='lower')\n",
    "        plt.show()\n",
    "        \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    \n",
    "    # based on inputs above, extract spectra from maps\n",
    "    \n",
    "    n_wavel = len(wavelengths_sorted) # number of wavelengths\n",
    "    wavel_spxs = np.copy(wavelengths_sorted) # just copying this instead of renaming bc lazy\n",
    "\n",
    "    # define bins based on n_mu (number of bins) and other info calculated earlier\n",
    "    if spec_type == 1:\n",
    "        d_mu = ((mu_max-mu_min)/n_bins) # size of mu bin\n",
    "        print('Size of mu bin:',d_mu)\n",
    "        \n",
    "    #elif spec_type == 2:\n",
    "    #    continue # add other spectral types here\n",
    "\n",
    "    # define bins w/ the size of bin (d_mu) in mu-space. not relevant yet\n",
    "    #d_mu = 0.1 # example, if defining by size of bin\n",
    "    \n",
    "    '''\n",
    "    For defining bins w/ size of mu bin and not number of bins\n",
    "    mu_max = 1.0\n",
    "    w_mu = 0.1\n",
    "    n_mu = int((mu_max-mu_min)/d_mu)\n",
    "    n_bins = n_mu*2+1\n",
    "    '''\n",
    "    \n",
    "    # utilize dictionaries to save spectra and corresponding geometry values for each wavelength.\n",
    "    \n",
    "    # make empty arrays for binning section. columns = bins, rows = wavelengths\n",
    "    extracted_spectrum_ave = np.zeros((n_bins,n_wavel))\n",
    "    extracted_lat_ave = np.zeros((n_bins,n_wavel))\n",
    "    extracted_long_ave = np.zeros((n_bins,n_wavel))\n",
    "    extracted_emiss_ave = np.zeros((n_bins,n_wavel))\n",
    "    extracted_solar_ave = np.zeros((n_bins,n_wavel))\n",
    "    extracted_azi_ave = np.zeros((n_bins,n_wavel))\n",
    "\n",
    "    for i_wavel in range(0,len(wavel_spxs)):\n",
    "        \n",
    "        print('Extracting spectra for',wavel_spxs[i_wavel],'microns...')\n",
    "        \n",
    "        # pull maps for this wavelength\n",
    "        # !!! just raw data here for spxs. make sure to convert to physical units later\n",
    "        spxs = map_dict[str(wavel_spxs[i_wavel])]['data_'+str(wavel_spxs[i_wavel])]\n",
    "        mu_spxs = map_dict[str(wavel_spxs[i_wavel])]['mu_'+str(wavel_spxs[i_wavel])]\n",
    "        lat_spxs = map_dict[str(wavel_spxs[i_wavel])]['latitude_final_'+str(wavel_spxs[i_wavel])]\n",
    "        long_spxs = map_dict[str(wavel_spxs[i_wavel])]['longitude_final_'+str(wavel_spxs[i_wavel])]\n",
    "        solar_spxs = map_dict[str(wavel_spxs[i_wavel])]['szen_'+str(wavel_spxs[i_wavel])]\n",
    "        zen_spxs = map_dict[str(wavel_spxs[i_wavel])]['zen_'+str(wavel_spxs[i_wavel])]\n",
    "        azimuth_spxs = map_dict[str(wavel_spxs[i_wavel])]['aphi_'+str(wavel_spxs[i_wavel])]\n",
    "        lcm_spxs = map_dict[str(wavel_spxs[i_wavel])]['lcm_'+str(wavel_spxs[i_wavel])] \n",
    "\n",
    "        # once lists are loaded, extract spectra\n",
    "        wavel = wavel_spxs[i_wavel]\n",
    "\n",
    "        # h = 0 # bin index, for assigning values in arrays. might need if meridian_switch = 0\n",
    "        \n",
    "        for i_mu in range(0,n_bins):\n",
    "            # calculate mu boundaries\n",
    "            # !! this is giving mu values above 1 which don't exist\n",
    "            mu_0 = mu_min + float(d_mu*i_mu)\n",
    "            mu_1 = mu_min + float(d_mu*i_mu) + w_mu\n",
    "            print('mu_0=',mu_0,'mu_1=',mu_1)\n",
    "\n",
    "            if meridian_switch == 1: # if averaging bins on either side of meridian\n",
    "\n",
    "                coords = np.where((lat_map<lat_max) & (lat_map>lat_min) & (mu_map>mu_0) & (mu_map<mu_1))\n",
    "                if plot_maps == 1:\n",
    "                    spxs_test = np.copy(spxs)\n",
    "                    spxs_test[coords] = np.nan\n",
    "                    plt.imshow(spxs_test,origin='lower')\n",
    "                    plt.title('extraction region for bin '+str(i_mu))\n",
    "                    plt.show()\n",
    "                    \n",
    "                # save average of the regions within coords to extracted_* arrays\n",
    "                extracted_spectrum_ave[i_mu,i_wavel] = np.mean(spxs[coords])\n",
    "                extracted_lat_ave[i_mu,i_wavel] = np.mean(lat_spxs[coords])\n",
    "                extracted_long_ave[i_mu,i_wavel] = np.mean(long_spxs[coords])\n",
    "                extracted_emiss_ave[i_mu,i_wavel] = np.mean(zen_spxs[coords])\n",
    "                extracted_solar_ave[i_mu,i_wavel] = np.mean(solar_spxs[coords])\n",
    "                extracted_azi_ave[i_mu,i_wavel] = np.mean(azimuth_spxs[coords])\n",
    "                \n",
    "            elif meridian_switch == 0:\n",
    "                print('Emma hasnt coded this yet, do not use')\n",
    "                # here's where lcm would be used. eg as condition for either side of lcm\n",
    "                return \n",
    " \n",
    "    # add distance-finding routine here. make array w number of bins to assign distances to\n",
    "    # !!!! update mu_max to stay below 1.\n",
    "    \n",
    "    return extracted_spectrum_ave, extracted_lat_ave, extracted_long_ave, extracted_emiss_ave, extracted_solar_ave, extracted_azi_ave, wavelengths_sorted, n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4a269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# example test\n",
    "extracted_spectrum_ave, extracted_lat_ave, extracted_long_ave, extracted_emiss_ave, extracted_solar_ave, extracted_azi_ave, wavelengths_sorted, n_bins = spextraction_images('/Users/emmadahl/Desktop/spextraction/spextraction_input_binned_lat.txt', '/Users/emmadahl/Desktop/spextraction/data_list_test.txt', '/Users/emmadahl/Desktop/spextraction/test_maps/', map_load=1, plot_maps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! size/overlap of mu bins look a bit wonky. probably has to do with overlap or mu_1 going above 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7175a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be a subroutine for spextraction\n",
    "\n",
    "def spectrum_file_maker(input_list, specfile, solarfile, file_format='Nemesis'):\n",
    "    '''\n",
    "    # !! need to make it so that text is saved to a file.\n",
    "    # !! need to generate solar spectrum file, or add routine here. there are spex-smoothed spectra in raddata but don't cover our wavelengths.\n",
    "    # !! need to figure out physical unit situation. how to convert to I/F or radiance???\n",
    "    # !! need an estimate of spectral error\n",
    "    \n",
    "    input_list - string, path+name of file containing images\n",
    "    specfile - string, path+name of spectrum file to be made and saved. \n",
    "    solarfile - file containing solar spectrum. !! need to generate this for guidedog\n",
    "    file_format - string, label for desired format of spectrum file. currently only coded for Nemesis spx files.\n",
    "    '''\n",
    "    \n",
    "    # pull spectra using spextraction_images\n",
    "    extracted_spectrum_ave, extracted_lat_ave, extracted_long_ave, extracted_emiss_ave, extracted_solar_ave, extracted_azi_ave, wavelengths, n_bins = spextraction_images('/Users/emmadahl/Desktop/spextraction/spextraction_input_binned_lat.txt','/Users/emmadahl/Desktop/spextraction/data_list_test.txt',map_save=1)\n",
    "    \n",
    "    # - - - - - - - - - - -\n",
    "    \n",
    "    if file_format == 'Nemesis':\n",
    "    \n",
    "        #r = distance_finder() # AU. Might need this to find radiance in loop later\n",
    "        \n",
    "        # add loading of solar file here. Needs to be included as auxiliary file, and same file as in runname.sol\n",
    "        F_sol = np.loadtxt(solarfile) # wavelength, solar radiance/luminosity\n",
    "        # interpolate at our data points. Ideally this will also be convolved with our filter functions\n",
    "        solar_func = interp1d(F_sol[:,0],F_sol[:,1])\n",
    "        F_solar = []\n",
    "        for g in wavelengths:\n",
    "            F_solar.append(solar_func(g))\n",
    "        \n",
    "        FWHM = 0\n",
    "        LATITUDE = np.mean(extracted_lat_ave) # the average latitude of all spectra in the file\n",
    "        LONGITUDE = np.mean(extracted_long_ave) # the average longitude of all spectra in the file\n",
    "        NGEOM = np.copy(n_bins)\n",
    "        NAV = 1\n",
    "        \n",
    "        file = open(specfile,'w')\n",
    "        # make top header\n",
    "        file.write('     '+str(FWHM)+'  '+str(np.round(LATITUDE,3))+'  '+str(np.round(LONGITUDE,3))+'  '+str(NGEOM )+' \\n')\n",
    "\n",
    "        # for spectra headers\n",
    "        NCONV = len(wavelengths)\n",
    "        NAV = 1\n",
    "\n",
    "        for p in range(0,n_bins):\n",
    "            \n",
    "            # define header for that mu bin\n",
    "            FLAT = np.mean(extracted_lat_ave[p,:])\n",
    "            FLON = np.mean(extracted_long_ave[p,:])\n",
    "            SOL_ANG = np.mean(extracted_solar_ave[p,:])\n",
    "            EMISS_ANG = np.mean(extracted_emiss_ave[p,:])\n",
    "            AZI_ANG = np.mean(extracted_azi_ave[p,:])\n",
    "            WGEOM = '1'\n",
    "\n",
    "            file.write('     '+str(NCONV)+' \\n')\n",
    "            file.write('     '+str(NAV)+' \\n')\n",
    "            file.write('     '+str(np.round(FLAT,3))+'  '+str(np.round(FLON,3))+'  '+str(np.round(SOL_ANG,3))+'  '+str(np.round(EMISS_ANG,3))+'  '+str(np.round(AZI_ANG,3))+'  '+str(WGEOM)+' \\n')\n",
    "\n",
    "            # print spectrum\n",
    "            for j in range(0,len(wavelengths)):\n",
    "                # raw spectrum value*OPAL correction*IF factor*radiance conversion\n",
    "                F_Sol_value = ufloat(F_Solar[j],F_Solar[j]*0.01) # assuming 1% error on solar spectrum\n",
    "\n",
    "                # !!! stand-in unit conversion, probably wrong.\n",
    "                spectrum_value_with_error = ufloat(spec[p,:][j],np.sqrt(spec[p,:][j]))*1e-7*(1/0.0001)*((F_Solar*1e-22)/(r**2)/math.pi/1000) #1e-22 from difference between thullier solar spec files\n",
    "\n",
    "                # print wavelength in microns, radiance, error:\n",
    "                file.write('     '+str(round(wavel_spxs[j],4))+'  '+ str(round(spectrum_value_with_error.nominal_value,12))+'  '+str(round(spectrum_value_with_error.std_dev,12))+' \\n')\n",
    "\n",
    "                # plot radiance spectra:\n",
    "                #plt.plot(wavel_spxs[j],spectrum_value_with_error.nominal_value,'.')\n",
    "            #plt.show()\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d43f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectrum_file_maker('/Users/emmadahl/Desktop/spextraction/data_list_test.txt', '/Users/emmadahl/Desktop/spextraction/jupiter.spx.test', file_format='Nemesis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
